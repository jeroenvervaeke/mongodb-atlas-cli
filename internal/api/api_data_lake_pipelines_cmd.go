// Copyright 2023 MongoDB Inc
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by OpenAPI Generator (https://openapi-generator.tech); DO NOT EDIT.

package api

import (
	"context"
	"encoding/json"
	"fmt"
	"io"
	"os"
	"time"

	"github.com/mongodb/mongodb-atlas-cli/internal/config"
	"github.com/spf13/afero"
	"github.com/spf13/cobra"
	"go.mongodb.org/atlas-sdk/v20230201008/admin"
)

type createPipelineOpts struct {
	client  *admin.APIClient
	groupId string

	filename string
	fs       afero.Fs
}

func (opts *createPipelineOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *createPipelineOpts) readData() (*admin.DataLakeIngestionPipeline, error) {
	var out *admin.DataLakeIngestionPipeline

	var buf []byte
	var err error
	if opts.filename == "" {
		buf, err = io.ReadAll(os.Stdin)
	} else {
		if exists, errExists := afero.Exists(opts.fs, opts.filename); !exists || errExists != nil {
			return nil, fmt.Errorf("file not found: %s", opts.filename)
		}
		buf, err = afero.ReadFile(opts.fs, opts.filename)
	}
	if err != nil {
		return nil, err
	}
	if err = json.Unmarshal(buf, &out); err != nil {
		return nil, err
	}
	return out, nil
}

func (opts *createPipelineOpts) run(ctx context.Context, w io.Writer) error {
	data, errData := opts.readData()
	if errData != nil {
		return errData
	}
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.CreatePipelineApiParams{
		GroupId: opts.groupId,

		DataLakeIngestionPipeline: data,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.CreatePipelineWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func createPipelineBuilder() *cobra.Command {
	opts := createPipelineOpts{
		fs: afero.NewOsFs(),
	}
	cmd := &cobra.Command{
		Use:   "createPipeline",
		Short: "Create One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)

	cmd.Flags().StringVarP(&opts.filename, "file", "f", "", "Path to an optional JSON configuration file if not passed stdin is expected")

	_ = cmd.MarkFlagRequired("groupId")
	return cmd
}

type deletePipelineOpts struct {
	client       *admin.APIClient
	groupId      string
	pipelineName string
}

func (opts *deletePipelineOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *deletePipelineOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.DeletePipelineApiParams{
		GroupId:      opts.groupId,
		PipelineName: opts.pipelineName,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.DeletePipelineWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func deletePipelineBuilder() *cobra.Command {
	opts := deletePipelineOpts{}
	cmd := &cobra.Command{
		Use:   "deletePipeline",
		Short: "Remove One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type deletePipelineRunDatasetOpts struct {
	client        *admin.APIClient
	groupId       string
	pipelineName  string
	pipelineRunId string
}

func (opts *deletePipelineRunDatasetOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *deletePipelineRunDatasetOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.DeletePipelineRunDatasetApiParams{
		GroupId:       opts.groupId,
		PipelineName:  opts.pipelineName,
		PipelineRunId: opts.pipelineRunId,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.DeletePipelineRunDatasetWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func deletePipelineRunDatasetBuilder() *cobra.Command {
	opts := deletePipelineRunDatasetOpts{}
	cmd := &cobra.Command{
		Use:   "deletePipelineRunDataset",
		Short: "Delete Pipeline Run Dataset",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)
	cmd.Flags().StringVar(&opts.pipelineRunId, "pipelineRunId", "", `Unique 24-hexadecimal character string that identifies a Data Lake Pipeline run.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	_ = cmd.MarkFlagRequired("pipelineRunId")
	return cmd
}

type getPipelineOpts struct {
	client       *admin.APIClient
	groupId      string
	pipelineName string
}

func (opts *getPipelineOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *getPipelineOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.GetPipelineApiParams{
		GroupId:      opts.groupId,
		PipelineName: opts.pipelineName,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.GetPipelineWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func getPipelineBuilder() *cobra.Command {
	opts := getPipelineOpts{}
	cmd := &cobra.Command{
		Use:   "getPipeline",
		Short: "Return One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type getPipelineRunOpts struct {
	client        *admin.APIClient
	groupId       string
	pipelineName  string
	pipelineRunId string
}

func (opts *getPipelineRunOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *getPipelineRunOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.GetPipelineRunApiParams{
		GroupId:       opts.groupId,
		PipelineName:  opts.pipelineName,
		PipelineRunId: opts.pipelineRunId,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.GetPipelineRunWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func getPipelineRunBuilder() *cobra.Command {
	opts := getPipelineRunOpts{}
	cmd := &cobra.Command{
		Use:   "getPipelineRun",
		Short: "Return One Data Lake Pipeline Run",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)
	cmd.Flags().StringVar(&opts.pipelineRunId, "pipelineRunId", "", `Unique 24-hexadecimal character string that identifies a Data Lake Pipeline run.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	_ = cmd.MarkFlagRequired("pipelineRunId")
	return cmd
}

type listPipelineRunsOpts struct {
	client        *admin.APIClient
	groupId       string
	pipelineName  string
	includeCount  bool
	itemsPerPage  int
	pageNum       int
	createdBefore string
}

func (opts *listPipelineRunsOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *listPipelineRunsOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	var createdBefore *time.Time
	var errCreatedBefore error
	if opts.createdBefore != "" {
		*createdBefore, errCreatedBefore = time.Parse(time.RFC3339, opts.createdBefore)
		if errCreatedBefore != nil {
			return errCreatedBefore
		}
	}

	params := &admin.ListPipelineRunsApiParams{
		GroupId:       opts.groupId,
		PipelineName:  opts.pipelineName,
		IncludeCount:  &opts.includeCount,
		ItemsPerPage:  &opts.itemsPerPage,
		PageNum:       &opts.pageNum,
		CreatedBefore: createdBefore,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.ListPipelineRunsWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func listPipelineRunsBuilder() *cobra.Command {
	opts := listPipelineRunsOpts{}
	cmd := &cobra.Command{
		Use:   "listPipelineRuns",
		Short: "Return All Data Lake Pipeline Runs from One Project",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)
	cmd.Flags().BoolVar(&opts.includeCount, "includeCount", true, `Flag that indicates whether the response returns the total number of items (**totalCount**) in the response.`)
	cmd.Flags().IntVar(&opts.itemsPerPage, "itemsPerPage", 100, `Number of items that the response returns per page.`)
	cmd.Flags().IntVar(&opts.pageNum, "pageNum", 1, `Number of the page that displays the current set of the total objects that the response returns.`)
	cmd.Flags().StringVar(&opts.createdBefore, "createdBefore", "", `If specified, Atlas returns only Data Lake Pipeline runs initiated before this time and date.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type listPipelineSchedulesOpts struct {
	client       *admin.APIClient
	groupId      string
	pipelineName string
}

func (opts *listPipelineSchedulesOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *listPipelineSchedulesOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.ListPipelineSchedulesApiParams{
		GroupId:      opts.groupId,
		PipelineName: opts.pipelineName,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.ListPipelineSchedulesWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func listPipelineSchedulesBuilder() *cobra.Command {
	opts := listPipelineSchedulesOpts{}
	cmd := &cobra.Command{
		Use:   "listPipelineSchedules",
		Short: "Return Available Ingestion Schedules for One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type listPipelineSnapshotsOpts struct {
	client         *admin.APIClient
	groupId        string
	pipelineName   string
	includeCount   bool
	itemsPerPage   int
	pageNum        int
	completedAfter string
}

func (opts *listPipelineSnapshotsOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *listPipelineSnapshotsOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	var completedAfter *time.Time
	var errCompletedAfter error
	if opts.completedAfter != "" {
		*completedAfter, errCompletedAfter = time.Parse(time.RFC3339, opts.completedAfter)
		if errCompletedAfter != nil {
			return errCompletedAfter
		}
	}

	params := &admin.ListPipelineSnapshotsApiParams{
		GroupId:        opts.groupId,
		PipelineName:   opts.pipelineName,
		IncludeCount:   &opts.includeCount,
		ItemsPerPage:   &opts.itemsPerPage,
		PageNum:        &opts.pageNum,
		CompletedAfter: completedAfter,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.ListPipelineSnapshotsWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func listPipelineSnapshotsBuilder() *cobra.Command {
	opts := listPipelineSnapshotsOpts{}
	cmd := &cobra.Command{
		Use:   "listPipelineSnapshots",
		Short: "Return Available Backup Snapshots for One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)
	cmd.Flags().BoolVar(&opts.includeCount, "includeCount", true, `Flag that indicates whether the response returns the total number of items (**totalCount**) in the response.`)
	cmd.Flags().IntVar(&opts.itemsPerPage, "itemsPerPage", 100, `Number of items that the response returns per page.`)
	cmd.Flags().IntVar(&opts.pageNum, "pageNum", 1, `Number of the page that displays the current set of the total objects that the response returns.`)
	cmd.Flags().StringVar(&opts.completedAfter, "completedAfter", "", `Date and time after which MongoDB Cloud created the snapshot. If specified, MongoDB Cloud returns available backup snapshots created after this time and date only. This parameter expresses its value in the ISO 8601 timestamp format in UTC.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type listPipelinesOpts struct {
	client  *admin.APIClient
	groupId string
}

func (opts *listPipelinesOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *listPipelinesOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.ListPipelinesApiParams{
		GroupId: opts.groupId,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.ListPipelinesWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func listPipelinesBuilder() *cobra.Command {
	opts := listPipelinesOpts{}
	cmd := &cobra.Command{
		Use:   "listPipelines",
		Short: "Return All Data Lake Pipelines from One Project",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)

	_ = cmd.MarkFlagRequired("groupId")
	return cmd
}

type pausePipelineOpts struct {
	client       *admin.APIClient
	groupId      string
	pipelineName string
}

func (opts *pausePipelineOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *pausePipelineOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.PausePipelineApiParams{
		GroupId:      opts.groupId,
		PipelineName: opts.pipelineName,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.PausePipelineWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func pausePipelineBuilder() *cobra.Command {
	opts := pausePipelineOpts{}
	cmd := &cobra.Command{
		Use:   "pausePipeline",
		Short: "Pause One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type resumePipelineOpts struct {
	client       *admin.APIClient
	groupId      string
	pipelineName string
}

func (opts *resumePipelineOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *resumePipelineOpts) run(ctx context.Context, w io.Writer) error {
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.ResumePipelineApiParams{
		GroupId:      opts.groupId,
		PipelineName: opts.pipelineName,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.ResumePipelineWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func resumePipelineBuilder() *cobra.Command {
	opts := resumePipelineOpts{}
	cmd := &cobra.Command{
		Use:   "resumePipeline",
		Short: "Resume One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type triggerSnapshotIngestionOpts struct {
	client       *admin.APIClient
	groupId      string
	pipelineName string

	filename string
	fs       afero.Fs
}

func (opts *triggerSnapshotIngestionOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *triggerSnapshotIngestionOpts) readData() (*admin.TriggerIngestionPipelineRequest, error) {
	var out *admin.TriggerIngestionPipelineRequest

	var buf []byte
	var err error
	if opts.filename == "" {
		buf, err = io.ReadAll(os.Stdin)
	} else {
		if exists, errExists := afero.Exists(opts.fs, opts.filename); !exists || errExists != nil {
			return nil, fmt.Errorf("file not found: %s", opts.filename)
		}
		buf, err = afero.ReadFile(opts.fs, opts.filename)
	}
	if err != nil {
		return nil, err
	}
	if err = json.Unmarshal(buf, &out); err != nil {
		return nil, err
	}
	return out, nil
}

func (opts *triggerSnapshotIngestionOpts) run(ctx context.Context, w io.Writer) error {
	data, errData := opts.readData()
	if errData != nil {
		return errData
	}
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.TriggerSnapshotIngestionApiParams{
		GroupId:      opts.groupId,
		PipelineName: opts.pipelineName,

		TriggerIngestionPipelineRequest: data,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.TriggerSnapshotIngestionWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func triggerSnapshotIngestionBuilder() *cobra.Command {
	opts := triggerSnapshotIngestionOpts{
		fs: afero.NewOsFs(),
	}
	cmd := &cobra.Command{
		Use:   "triggerSnapshotIngestion",
		Short: "Trigger on demand snapshot ingestion",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)

	cmd.Flags().StringVarP(&opts.filename, "file", "f", "", "Path to an optional JSON configuration file if not passed stdin is expected")

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

type updatePipelineOpts struct {
	client       *admin.APIClient
	groupId      string
	pipelineName string

	filename string
	fs       afero.Fs
}

func (opts *updatePipelineOpts) preRun() (err error) {
	opts.client, err = newClientWithAuth()
	return err
}

func (opts *updatePipelineOpts) readData() (*admin.DataLakeIngestionPipeline, error) {
	var out *admin.DataLakeIngestionPipeline

	var buf []byte
	var err error
	if opts.filename == "" {
		buf, err = io.ReadAll(os.Stdin)
	} else {
		if exists, errExists := afero.Exists(opts.fs, opts.filename); !exists || errExists != nil {
			return nil, fmt.Errorf("file not found: %s", opts.filename)
		}
		buf, err = afero.ReadFile(opts.fs, opts.filename)
	}
	if err != nil {
		return nil, err
	}
	if err = json.Unmarshal(buf, &out); err != nil {
		return nil, err
	}
	return out, nil
}

func (opts *updatePipelineOpts) run(ctx context.Context, w io.Writer) error {
	data, errData := opts.readData()
	if errData != nil {
		return errData
	}
	if opts.groupId == "" {
		opts.groupId = config.ProjectID()
	}

	params := &admin.UpdatePipelineApiParams{
		GroupId:      opts.groupId,
		PipelineName: opts.pipelineName,

		DataLakeIngestionPipeline: data,
	}

	resp, _, err := opts.client.DataLakePipelinesApi.UpdatePipelineWithParams(ctx, params).Execute()
	if err != nil {
		return err
	}

	prettyJSON, errJson := json.MarshalIndent(resp, "", " ")
	if errJson != nil {
		return errJson
	}

	_, err = fmt.Fprintln(w, string(prettyJSON))
	return err
}

func updatePipelineBuilder() *cobra.Command {
	opts := updatePipelineOpts{
		fs: afero.NewOsFs(),
	}
	cmd := &cobra.Command{
		Use:   "updatePipeline",
		Short: "Update One Data Lake Pipeline",
		PreRunE: func(cmd *cobra.Command, args []string) error {
			return opts.preRun()
		},
		RunE: func(cmd *cobra.Command, args []string) error {
			return opts.run(cmd.Context(), cmd.OutOrStdout())
		},
	}
	cmd.Flags().StringVar(&opts.groupId, "groupId", "", `Unique 24-hexadecimal digit string that identifies your project.`)
	cmd.Flags().StringVar(&opts.pipelineName, "pipelineName", "", `Human-readable label that identifies the Data Lake Pipeline.`)

	cmd.Flags().StringVarP(&opts.filename, "file", "f", "", "Path to an optional JSON configuration file if not passed stdin is expected")

	_ = cmd.MarkFlagRequired("groupId")
	_ = cmd.MarkFlagRequired("pipelineName")
	return cmd
}

func dataLakePipelinesBuilder() *cobra.Command {
	cmd := &cobra.Command{
		Use:   "dataLakePipelines",
		Short: `Returns, adds, edits, and removes Atlas Data Lake Pipelines and associated runs.`,
	}
	cmd.AddCommand(
		createPipelineBuilder(),
		deletePipelineBuilder(),
		deletePipelineRunDatasetBuilder(),
		getPipelineBuilder(),
		getPipelineRunBuilder(),
		listPipelineRunsBuilder(),
		listPipelineSchedulesBuilder(),
		listPipelineSnapshotsBuilder(),
		listPipelinesBuilder(),
		pausePipelineBuilder(),
		resumePipelineBuilder(),
		triggerSnapshotIngestionBuilder(),
		updatePipelineBuilder(),
	)
	return cmd
}
